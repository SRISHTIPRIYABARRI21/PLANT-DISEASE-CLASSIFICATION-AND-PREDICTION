{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nimport time\nimport random\n\nimport torch\nimport torchvision\n\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\n\nfrom torchvision import transforms, datasets\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom timeit import default_timer as timer\nfrom typing import Dict, List","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-11T12:04:22.786278Z","iopub.execute_input":"2024-10-11T12:04:22.786742Z","iopub.status.idle":"2024-10-11T12:04:29.066565Z","shell.execute_reply.started":"2024-10-11T12:04:22.786699Z","shell.execute_reply":"2024-10-11T12:04:29.065286Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:05:30.190782Z","iopub.execute_input":"2024-10-11T12:05:30.191131Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c789b671660>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c789b671960>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c789b671c00>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision.models as models\nfrom torchsummary import summary","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    from torchinfo import summary\n    print(\"[INFO] torchinfo imported successfully\")\nexcept:\n    print(\"[INFO] Could not find torchinfo. Installing it.\")\n    !pip install -q torchinfo\n    from torchinfo import summary\n    print(\"[INFO] torchinfo installed and imported successfully.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# setting device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# access the dataset directory\ndataset_dir = Path(\"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\")\n\nprint(dataset_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# access train and validation directory\ntrain_dir = dataset_dir / \"train\"\nval_dir = dataset_dir / \"valid\"\ntest_dir = Path(\"/kaggle/input/new-plant-diseases-dataset/test/test\")\n\nprint(f\"Train Directory : {train_dir}\")\nprint(f\"Validation Directory : {val_dir}\")\nprint(f\"Test Directory : {test_dir}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_class_train = len(os.listdir(train_dir))\ntotal_class_val = len(os.listdir(val_dir))\ntotal_test = len(os.listdir(test_dir))\n\nprint(f\"Total of Train Data Classes: {total_class_train} classes\")\nprint(f\"Total of Validation Data Classes: {total_class_val} classes\")\nprint(f\"Total of Test Data: {total_test} images\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# display data distribution\ndef count_data_per_class(path):\n    classes = sorted(os.listdir(path))\n    class_counts = {}\n    for cls in classes:\n        class_path = os.path.join(path, cls)\n        class_counts[cls] = len(os.listdir(class_path))\n    return class_counts\n\n# calculate total data of each class\ntrain_class_counts = count_data_per_class(train_dir)\nval_class_counts = count_data_per_class(val_dir)\n\n# create dataframe class count\ntrain_counts_df = pd.DataFrame.from_dict(train_class_counts, orient=\"index\", columns=[\"Count\"])\nval_counts_df = pd.DataFrame.from_dict(val_class_counts, orient=\"index\", columns=[\"Count\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Total Image for Training: {sum(train_class_counts.values())} images\")\nprint(f\"Total Image for Validation: {sum(val_class_counts.values())} images\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_counts_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_counts_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# display barplot for train data\nplt.figure(figsize=(10, 10))\nsns.barplot(data=train_counts_df, x=train_counts_df.index, y=\"Count\", color=\"lime\")\nplt.title(\"Total Data per Class in Train Data\")\nplt.xlabel(\"Plant Diseases\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=90)\n\n# get the current axes to make the number label on top each bar\nax = plt.gca()\n\n# add count labels on top of each bar\nfor p in ax.patches:\n    ax.text(p.get_x()+p.get_width()/2., # the count label position is center of each bar (x-coordinate)\n            p.get_height()+10, # the count label offset of each bar (y-coordinate)\n            '{:1.0f}'.format(p.get_height()), # get number of each bar height as count label\n            ha=\"center\") # the orientation of count label text is center horizontal\n\n# saving plot\nplt.savefig(\"Total Data per Class in Train Data.jpg\")\n\n# show the plot\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# display barplot for validation data\nplt.figure(figsize=(20, 10))\nsns.barplot(data=val_counts_df, x=val_counts_df.index, y=\"Count\", color=\"cyan\")\nplt.title(\"Total Data per Class in Validation Data\")\nplt.xlabel(\"Plant Diseases\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=90)\n\n# get the current axes to make the number label on top each bar\nax = plt.gca()\n\n# add count labels on top of each bar\nfor p in ax.patches:\n    ax.text(p.get_x()+p.get_width()/2., # the count label position is center of each bar (x-coordinate)\n            p.get_height()+3, # the count label offset of each bar (y-coordinate)\n            '{:1.0f}'.format(p.get_height()), # get number of each bar height as count label\n            ha=\"center\") # the orientation of count label text is center horizontal\n\n# saving plot\nplt.savefig(\"Total Data per Class in Validation Data.jpg\")\n\n# show the plot\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# display plant types and diseases\nall_diseases = sorted(os.listdir(train_dir))\n\nplants = []\nfor cls in all_diseases:\n    plant = cls.split(\"___\")[0]\n    if plant not in plants:\n        plants.append(plant)\n\nnum_plants = len(plants)\nprint(f\"Number of Plants: {num_plants} plants\")\nprint(\"Kind of Plants: \")\nfor i, plant in enumerate(plants):\n    print(f\"{i+1}. {plant}\")\n\ndiseases = []\nfor cls in all_diseases:\n    disease = cls.split(\"___\")[1]\n    if disease not in diseases:\n        if disease != \"healthy\":\n            diseases.append(disease)\n    \nnum_diseases = len(diseases)\nprint(f\"\\nNumber of Diseases: {num_diseases} diseases\")\nprint(\"Kind of Diseases: \")\nfor i, disease in enumerate(diseases):\n    print(f\"{i+1}. {disease}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# display some images\nrandom.seed(33)\n\n# get all of the image paths\nimage_path_list = list(dataset_dir.glob(\"*/*/*.jpg\"))\n\n# choose 20 images paths randomly\nrandom_image_paths = random.sample(image_path_list, 20)\n\n# define the subplot\nfig, axes = plt.subplots(nrows=10, ncols=2, figsize=(10, 40))\n\n# display 20 images randomly\nfor i, ax in enumerate(axes.flat):\n    random_image_path = random_image_paths[i] # get image path\n    image_class = random_image_path.parent.stem # get image class from path name as label\n    image = Image.open(random_image_path) # open image\n    ax.imshow(image) # display image on subplot\n    \n    # add label and shape of image\n    ax.set_title(f\"Label: {image_class}\\nShape: {image.height}x{image.width}x{3 if image.mode == 'RGB' else 1}\")\n    ax.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create data transformation based on ResNet50 model (ResNet50_Weights.IMAGENET1K_V2)\ntrain_transform_rn50 = transforms.Compose([\n    transforms.Resize(size=232, interpolation=transforms.InterpolationMode.BILINEAR),\n    transforms.CenterCrop(size=224),\n    transforms.RandomRotation(45), # augmentation: random rotation 45 degree\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform_rn50 = transforms.Compose([\n    transforms.Resize(size=232, interpolation=transforms.InterpolationMode.BILINEAR),\n    transforms.CenterCrop(size=224),\n    # do not augment in validation data\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create data transformation based on EfficientNet V2 model (EfficientNet_V2_S_Weights.IMAGENET1K_V1)\ntrain_transform_ev2 = transforms.Compose([\n    transforms.Resize(size=384, interpolation=transforms.InterpolationMode.BILINEAR),\n    transforms.CenterCrop(size=384),\n    transforms.RandomRotation(45), # augmentation: random rotation 45 degree\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform_ev2 = transforms.Compose([\n    transforms.Resize(size=384, interpolation=transforms.InterpolationMode.BILINEAR),\n    transforms.CenterCrop(size=384),\n    # do not augment in validation data\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create ImageFolder for prepare dataset\n# this method is easier than custom dataset, because dataset has already split by folder train and validation\n\n# ImageFolder for ResNet50 model\ntrain_dataset_rn50 = datasets.ImageFolder(root=train_dir, transform=train_transform_rn50)\nval_dataset_rn50 = datasets.ImageFolder(root=val_dir, transform=val_transform_rn50)\n\n# ImageFolder for EfficientNet V2 model\ntrain_dataset_ev2 = datasets.ImageFolder(root=train_dir, transform=train_transform_ev2)\nval_dataset_ev2 = datasets.ImageFolder(root=val_dir, transform=val_transform_ev2)\n\n# display classes of ImageFolder dataset\nprint(f\"Dataset Classes: {len(train_dataset_ev2.classes)}\\n\")\ntrain_dataset_ev2.classes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create DataLoader for ResNet50 model\ntrain_dataloader_rn50 = DataLoader(train_dataset_rn50,\n                                   batch_size=32,\n                                   num_workers=2,\n                                   shuffle=True)\n\nval_dataloader_rn50 = DataLoader(val_dataset_rn50,\n                                 batch_size=32,\n                                 num_workers=2,\n                                 shuffle=False) # do not shuffle on validation data\n\n# create DataLoader for EfficientNet V2 model\ntrain_dataloader_ev2 = DataLoader(train_dataset_ev2,\n                                  batch_size=32,\n                                  num_workers=2,\n                                  shuffle=True)\n\nval_dataloader_ev2 = DataLoader(val_dataset_ev2,\n                                batch_size=32,\n                                num_workers=2,\n                                shuffle=False) # do not shuffle on validation data\n\n\nprint(f\"Number of Train Dataloader: {len(train_dataloader_ev2)} batches\")\nprint(f\"Number of Validation Dataloader: {len(val_dataloader_ev2)} batches\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# looking information inside dataloader has made: ResNet50\n\n# get the batch sample in the dataloader\n# dataloader contains input and output (feature and label)\nimages, labels = next(iter(train_dataloader_rn50))\n\n# get the number of batches in the dataloader\nnum_batches = len(train_dataloader_rn50)\n\n# print out the summary\nprint(\"[DATALOADER FOR RESNET50 MODEL]\\n\")\nprint(f\"Train Dataloader = {train_dataloader_rn50}\\n\")\nprint(f\"Batch Sample:\\nImage Shape = {images.shape}\\nLabel Shape = {labels.shape}\\nLabels = {labels.tolist()}\")\nprint(f\"Number of Batches = {num_batches} batches\")\nprint(f\"Number of All Data = {32*num_batches} images\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# looking information inside dataloader has made: EfficientNet V2\n\n# get the batch sample in the dataloader\n# dataloader contains input and output (feature and label)\nimages, labels = next(iter(train_dataloader_ev2))\n\n# get the number of batches in the dataloader\nnum_batches = len(train_dataloader_ev2)\n\n# print out the summary\nprint(\"[DATALOADER FOR EFFICIENTNET V2 MODEL]\\n\")\nprint(f\"Train Dataloader = {train_dataloader_ev2}\\n\")\nprint(f\"Batch Sample:\\nImage Shape = {images.shape}\\nLabel Shape = {labels.shape}\\nLabels = {labels.tolist()}\")\nprint(f\"Number of Batches = {num_batches} batches\")\nprint(f\"Number of All Data = {32*num_batches} images\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# visualize dataloader: ResNet50\ntorch.manual_seed(33)\n\n# visualize the sample of train dataloader\nbatch_images, batch_labels = next(iter(train_dataloader_rn50))\n\n# function for displaying 10 images randomly from dataloader\ndef display_images(images, labels, class_names, nrows=5, ncols=2):\n    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 20))\n    for i, ax in enumerate(axes.flat):\n        img = images[i].permute(1, 2, 0).numpy()\n        img = (img - np.min(img)) / (np.max(img) - np.min(img)) # normalization display to 0 - 1\n        ax.imshow(img)\n        # get class name from label\n        label_idx = labels[i].item()\n        class_name = class_names[label_idx]\n        # display class name\n        ax.set_title(f\"Label: {class_name}\\nShape: {img.shape}\")\n        ax.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n# display images\ndisplay_images(batch_images, batch_labels, train_dataset_rn50.classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# visualize dataloader: EfficientNet V2\ntorch.manual_seed(33)\n\n# visualize the sample of train dataloader\nbatch_images, batch_labels = next(iter(train_dataloader_ev2))\n\n# function for displaying 10 images randomly from dataloader\ndef display_images(images, labels, class_names, nrows=5, ncols=2):\n    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 20))\n    for i, ax in enumerate(axes.flat):\n        img = images[i].permute(1, 2, 0).numpy()\n        img = (img - np.min(img)) / (np.max(img) - np.min(img)) # normalization display to 0 - 1\n        ax.imshow(img)\n        # get class name from label\n        label_idx = labels[i].item()\n        class_name = class_names[label_idx]\n        # display class name\n        ax.set_title(f\"Label: {class_name}\\nShape: {img.shape}\")\n        ax.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n# display images\ndisplay_images(batch_images, batch_labels, train_dataset_ev2.classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load pre-trained ResNet50 model: ResNet50_Weights.IMAGENET1K_V2\nrn50_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n\n# modify fully connected layer\nrn50_model.fc = nn.Sequential(nn.Linear(in_features=rn50_model.fc.in_features, out_features=38))\n\n# freeze pre-trained layers\nfor param in rn50_model.parameters():\n    param.requires_grad = False\n\n# unfreeze fully connected layers\nfor param in rn50_model.fc.parameters():\n    param.requires_grad = True\n\n# put model into device\nrn50_model = rn50_model.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# display ResNet50 model summary\nsummary(model=rn50_model,\n        input_size=(32, 3, 224, 224),\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load pre-trained EfficientNet V2 model: EfficientNet_V2_S_Weights.IMAGENET1K_V1\nev2_model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n\n# modify fully connected layer\nev2_model.classifier = nn.Sequential(nn.Linear(in_features=1280, out_features=38))\n\n# freeze pre-trained layers\nfor param in ev2_model.parameters():\n    param.requires_grad = False\n\n# unfreeze fully connected layers\nfor param in ev2_model.classifier.parameters():\n    param.requires_grad = True\n\n# put model into device\nev2_model = ev2_model.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# display EfficientNet V2 model summary\nsummary(model=ev2_model,\n        input_size=(32, 3, 384, 384),\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# use CrossEntropyLoss() for multiclass classification task\nloss_fn = nn.CrossEntropyLoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Adam optimizer\noptim_rn50 = Adam(params=rn50_model.parameters(), lr=0.001)\noptim_ev2 = Adam(params=ev2_model.parameters(), lr=0.001)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train loop function\ndef train_step(model: torch.nn.Module,\n               dataloader: torch.utils.data.DataLoader,\n               loss_fn: torch.nn.Module,\n               optimizer: torch.optim.Optimizer):\n    # put model in train mode\n    model.train()\n\n    # setup train loss and train accuracy values\n    train_loss, train_acc = 0, 0\n\n    # loop through data loader data batches\n    for batch, (X, y) in enumerate(dataloader):\n        # send data to target device\n        X, y = X.to(device), y.to(device)\n\n        # 1. forward pass\n        y_pred = model(X)\n\n        # 2. calculate  and accumulate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss.item()\n\n        # 3. optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. loss backward\n        loss.backward()\n\n        # 5. optimizer step\n        optimizer.step()\n\n        # 6. calculate and accumulate accuracy metric across all batches\n        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n\n    # adjust metrics to get average loss and accuracy per batch\n    train_loss = train_loss / len(dataloader)\n    train_acc = train_acc / len(dataloader)\n    return train_loss, train_acc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# validation loop test\ndef val_step(model: torch.nn.Module,\n                    dataloader: torch.utils.data.DataLoader,\n                    loss_fn: torch.nn.Module):\n    # put model in eval mode\n    model.eval()\n\n    # setup test loss and test accuracy values\n    val_loss, val_acc = 0, 0\n\n    # turn on inference context manager\n    with torch.inference_mode():\n        # loop through DataLoader batches\n        for batch, (X, y) in enumerate(dataloader):\n            # send data to target device\n            X, y = X.to(device), y.to(device)\n\n            # 1. forward pass\n            val_pred_logits = model(X)\n\n            # 2. calculate and accumulate loss\n            loss = loss_fn(val_pred_logits, y)\n            val_loss += loss.item()\n\n            # 3. calculate and accumulate accuracy\n            val_pred_labels = val_pred_logits.argmax(dim=1)\n            val_acc += ((val_pred_labels == y).sum().item()/len(val_pred_labels))\n\n    # adjust metrics to get average loss and accuracy per batch\n    val_loss = val_loss / len(dataloader)\n    val_acc = val_acc / len(dataloader)\n    return val_loss, val_acc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train process\n\n# 1. take in various parameters required for training and test steps\ndef train_process(model: torch.nn.Module,\n                  train_dataloader: torch.utils.data.DataLoader,\n                  val_dataloader: torch.utils.data.DataLoader,\n                  optimizer: torch.optim.Optimizer,\n                  loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n                  epochs: int = 5):\n\n    # 2. create empty results dictionary\n    results = {\"train_loss\": [],\n        \"train_acc\": [],\n        \"val_loss\": [],\n        \"val_acc\": []\n    }\n\n    # 3. loop through training and testing steps for a number of epochs\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc = train_step(model=model,\n                                           dataloader=train_dataloader,\n                                           loss_fn=loss_fn,\n                                           optimizer=optimizer)\n        val_loss, val_acc = val_step(model=model,\n                                     dataloader=val_dataloader,\n                                     loss_fn=loss_fn)\n\n        # 4. print out what's happening\n        print(\n            f\"Epoch: {epoch+1} | \"\n            f\"train_loss: {train_loss:.4f} | \"\n            f\"train_acc: {train_acc:.4f} | \"\n            f\"val_loss: {val_loss:.4f} | \"\n            f\"val_acc: {val_acc:.4f}\"\n        )\n\n        # 5. update results dictionary\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"val_loss\"].append(val_loss)\n        results[\"val_acc\"].append(val_acc)\n\n    # 6. return the filled results at the end of the epochs\n    return results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# set random seeds\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\n# set number of epochs\nNUM_EPOCHS = 5\n\n# start the timer\nstart_time = timer()\n\n# train fine tuning ResNet50 model\nrn50_results = train_process(model=rn50_model,\n                             train_dataloader=train_dataloader_rn50,\n                             val_dataloader=val_dataloader_rn50,\n                             optimizer=optim_rn50,\n                             loss_fn=loss_fn,\n                             epochs=NUM_EPOCHS)\n\n# end the timer and print out how long it took\nend_time = timer()\nprint(f\"Total Training Time: {end_time-start_time:.3f} seconds\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# set random seeds\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\n# set number of epochs\nNUM_EPOCHS = 5\n\n# start the timer\nstart_time = timer()\n\n# train fine tuning ResNet50 model\nev2_results = train_process(model=ev2_model,\n                            train_dataloader=train_dataloader_ev2,\n                            val_dataloader=val_dataloader_ev2,\n                            optimizer=optim_ev2,\n                            loss_fn=loss_fn,\n                            epochs=NUM_EPOCHS)\n\n# end the timer and print out how long it took\nend_time = timer()\nprint(f\"Total Training Time: {end_time-start_time:.3f} seconds\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# creat plot function for display result of training process\ndef plot_loss_curves(results: Dict[str, List[float]], suptitle=None, save=\"graph.jpg\"):\n    \"\"\"Plots training curves of a results dictionary.\n\n    Args:\n        results (dict): dictionary containing list of values, e.g.\n            {\"train_loss\": [...],\n             \"train_acc\": [...],\n             \"test_loss\": [...],\n             \"test_acc\": [...]}\n    \"\"\"\n\n    # get the loss values of the results dictionary (training and validation)\n    loss = results[\"train_loss\"]\n    val_loss = results[\"val_loss\"]\n\n    # get the accuracy values of the results dictionary (training and validation)\n    accuracy = results[\"train_acc\"]\n    val_accuracy = results[\"val_acc\"]\n\n    # figure out how many epochs there were\n    epochs = range(len(results[\"train_loss\"]))\n\n    # setup a plot\n    plt.figure(figsize=(12, 4))\n\n    # plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, loss, label=\"train_loss\")\n    plt.plot(epochs, val_loss, label=\"val_loss\")\n    plt.ylabel(\"Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n\n    # plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n    plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n    plt.ylabel(\"Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n\n    plt.suptitle(suptitle)\n    \n    # save graph\n    plt.savefig(save)\n\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plotting loss and accuracy from ResNet50 model results\nplot_loss_curves(rn50_results, suptitle=\"Result of ResNet50\", save=\"Result of ResNet50.jpg\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plotting loss and accuracy from EfficientNet V2 model results\nplot_loss_curves(ev2_results, suptitle=\"Result of EfficientNet V2\", save=\"Result of EfficientNet V2.jpg\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. create models directory\nmodel_path = Path(\"/kaggle/working/\")\nmodel_path.mkdir(parents=True, exist_ok=True)\n\n# 2. create model save path\nmodel_name = \"01_plant_diseases_classification_pytorch_rn50.pth\"\nmodel_save_path = model_path / model_name\n\n# 3. save the model state dict\nprint(f\"Saving model to: {model_save_path}\")\ntorch.save(obj=rn50_model.state_dict(), # only saving the state_dict() only saves the models learned parameters\n           f=model_save_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# making prediction on single image\n\n# load the trained ResNet50 model\n# do not put model into device\npath_model = \"/kaggle/working/01_plant_diseases_classification_pytorch_rn50.pth\"\nmodel = resnet50(weights=None)\nmodel.fc = nn.Sequential(nn.Linear(in_features=model.fc.in_features, out_features=38))\nmodel.load_state_dict(torch.load(path_model))\nmodel.eval()\n\n# define class labels\nclass_labels = train_dataset_rn50.classes\n\n# define the transfomation for the test images (same as transformation for validation data)\npreprocess = transforms.Compose([\n    transforms.Resize(size=232, interpolation=transforms.InterpolationMode.BILINEAR),\n    transforms.CenterCrop(size=224),\n    # do not augment in test data\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# prediction function on single image\ndef predict_image(image_path, model):\n    # open and preprocess the image\n    image = Image.open(image_path)\n    image_tensor = preprocess(image)\n    image_tensor = image_tensor.unsqueeze(0)  # add batch dimension\n\n    # make prediction\n    with torch.no_grad():\n        outputs = model(image_tensor)\n        _, predicted = torch.max(outputs, 1)\n        confidence = torch.nn.functional.softmax(outputs, dim=1)[0] * 100\n        predicted_label = class_labels[predicted.item()]\n\n    # display the image with prediction and confidence\n    plt.imshow(image)\n    plt.title(f\"Prediction: {predicted_label}, Confidence: {confidence[predicted.item()]:.2f}%\")\n    plt.axis(\"off\")\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# apple cedar rust prediction\nimage_path = \"/kaggle/input/new-plant-diseases-dataset/test/test/AppleCedarRust4.JPG\"\npredict_image(image_path, model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# apple scab prediction\nimage_path = \"/kaggle/input/new-plant-diseases-dataset/test/test/AppleScab2.JPG\"\npredict_image(image_path, model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# corn common rust prediction\nimage_path = \"/kaggle/input/new-plant-diseases-dataset/test/test/CornCommonRust1.JPG\"\npredict_image(image_path, model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# potato early blight prediction\nimage_path = \"/kaggle/input/new-plant-diseases-dataset/test/test/PotatoEarlyBlight3.JPG\"\npredict_image(image_path, model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# potato healthy prediction\nimage_path = \"/kaggle/input/new-plant-diseases-dataset/test/test/PotatoHealthy1.JPG\"\npredict_image(image_path, model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tomato healthy prediction\nimage_path = \"/kaggle/input/new-plant-diseases-dataset/test/test/TomatoHealthy1.JPG\"\npredict_image(image_path, model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tomato yellow curl virus prediction\nimage_path = \"/kaggle/input/new-plant-diseases-dataset/test/test/TomatoYellowCurlVirus6.JPG\"\npredict_image(image_path, model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}